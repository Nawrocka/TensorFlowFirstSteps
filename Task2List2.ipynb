{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import load_img\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom matplotlib import pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Dropout, Dense, MaxPooling2D, Flatten\nimport random\nimport os\nfrom zipfile import ZipFile\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Conv2D, MaxPooling2D\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport zipfile\n\nwith zipfile.ZipFile(\"../input/dogs-vs-cats/train.zip\",\"r\") as z:\n    z.extractall(\".\")\n    \nwith zipfile.ZipFile(\"../input/dogs-vs-cats/test1.zip\",\"r\") as z:\n    z.extractall(\".\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = \"./train/\"\ntest_dir = \"./test1/\"\n\nDtrain = os.listdir(train_dir)\ncategories = []\nfor filename in Dtrain:\n    category = filename.split(\".\")[0]\n    if category == \"dog\":\n        categories.append(\"dog\")\n    else:\n        categories.append(\"cat\")\ndf = pd.DataFrame({\n    \"filename\" : Dtrain,\n    \"category\" : categories\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.head())\nprint(df.tail())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfCat = df[df[\"category\"] == 'cat'].head(2000)\ndfTestCat = dfCat.head(500)\ndfCat = dfCat.iloc[500:,]\ndfValCat = dfCat.head(500)\ndfCat = dfCat.iloc[500:,]\nprint(dfCat.shape)\nprint(dfValCat.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfDog = df[df[\"category\"] == 'dog'].head(2000)\ndfTestDog = dfDog.head(500)\ndfDog = dfDog.iloc[500:,]\ndfValDog = dfDog.head(500)\ndfDog = dfDog.iloc[500:,]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"frames = [dfCat, dfDog] \nframes2 = [dfValCat, dfValDog]\nframes3 = [dfTestCat, dfTestDog]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = pd.concat(frames)\ndf2Val = pd.concat(frames2)\ndf2Test= pd.concat(frames3)\nprint(df2.head())\nprint(df2.tail())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I need shuffle this data\n#The frac keyword argument specifies the fraction of rows to return in the random sample, so frac=1 means return all rows (in random order).\n#Here, specifying drop=True prevents .reset_index from creating a column containing the old index entries.\ndf2 = df2.sample(frac=1).reset_index(drop=True)\ndf2Val = df2Val.sample(frac=1).reset_index(drop=True)\ndf2Test = df2Test.sample(frac=1).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df2.head())\nprint(df2.tail())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#I should it named test not validate because during training model I split 0,25 of data as validation data\n#from sklearn.model_selection import train_test_split\n\n#train_df, validate_df = train_test_split(df2, test_size = 0.25, random_state = 42)\n#train_df = train_df.reset_index(drop=True)\n#validate_df = validate_df.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.category.value_counts().plot.bar()\nplt.title(str(len(df2[df2['category'] == 'cat']))+\" cats\" + \" | \" +str(len(df2[df2['category'] == 'dog']))+\" dogs\", fontsize=18)\nplt.ylabel(len(df2), fontsize = 14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2Val.category.value_counts().plot.bar()\nplt.ylabel(len(df2Val), fontsize = 14)\nplt.title(str(len(df2Val[df2Val['category'] == 'dog']))+\" Dogs  |  \"+str((len(df2Val[df2Val['category'] == 'cat'])))+\" Cats\", fontsize=18)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2Test.category.value_counts().plot.bar()\nplt.ylabel(len(df2Test), fontsize = 14)\nplt.title(str(len(df2Test[df2Test['category'] == 'cat']))+\" Cats  |  \"+str((len(df2Test[df2Test['category'] == 'dog'])))+\" Dogs\", fontsize=18)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nmain_dir = \"/kaggle/working/\"\ntrain_dir = \"train\"\npath = os.path.join(main_dir,train_dir)\nconvert = lambda category : int(category == 'dog')\nX=[]\ny=[]\n\n \ndef create_test_data(path):\n    for t in df2['filename']:\n        print(t)\n        category = t.split(\".\")[0]\n        category = convert(category)\n        img_array = cv2.imread(os.path.join(path,t),cv2.IMREAD_GRAYSCALE)\n        print(img_array)\n        new_img_array = cv2.resize(img_array, dsize=(80, 80))\n        X.append(new_img_array)\n        y.append(category)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_test_data(path)\nX_train = np.array(X).reshape(-1, 80,80,1)\ny_train = np.array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test=[]\ny_test=[]\n#def create_test_data(path):\n    for t in df2Test['filename']:\n        print(t)\n        category = t.split(\".\")[0]\n        category = convert(category)\n        img_array = cv2.imread(os.path.join(path,t),cv2.IMREAD_GRAYSCALE)\n        print(img_array)\n        new_img_array = cv2.resize(img_array, dsize=(80, 80))\n        X_test.append(new_img_array)\n        y_test.append(category)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_test_data(path)\nX_test = np.array(X_test).reshape(-1, 80,80,1)\ny_test = np.array(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_val=[]\ny_val=[]\n#def create_test_data(path):\n    for t in df2Val['filename']:\n        print(t)\n        category = t.split(\".\")[0]\n        category = convert(category)\n        img_array = cv2.imread(os.path.join(path,t),cv2.IMREAD_GRAYSCALE)\n        print(img_array)\n        new_img_array = cv2.resize(img_array, dsize=(80, 80))\n        X_val.append(new_img_array)\n        y_val.append(category)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_test_data(path)\nX_val = np.array(X_val).reshape(-1, 80,80,1)\ny_val = np.array(y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_train[1])\nprint(y_train[1])\nprint(X_val.shape)\nprint(y_val.shape)\nprint(X_test.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalize data - as I can see abowe, every pixel is in scale 0-255 it's not optimized to process by comp, better is 0-1\nX_train = X_train/255.0\nX_test = X_test/255.0\nX_val = X_val/255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32,(3,3), activation = 'relu', input_shape = X_train.shape[1:]))\nmodel.add((MaxPooling2D(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3,3), activation=\"relu\"))\nmodel.add((MaxPooling2D(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3,3), activation=\"relu\"))\nmodel.add((MaxPooling2D(2,2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(32, activation=\"relu\"))\n\nmodel.add(Dense(1, activation=\"sigmoid\"))\n\nmodel.compile(optimizer=\"adam\",\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\ndot_img_file = '/tmp/model_1.png'\ntf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.utils import np_utils\n\nnum_classes=len(np.unique(y_train))\ny_train=keras.utils.to_categorical(y_train, num_classes)\ny_test=keras.utils.to_categorical(y_test,num_classes)\ny_val=keras.utils.to_categorical(y_val,num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n# Adds a densely-connected layer with 64 units to the model:\nmodel.add(Conv2D(64,(3,3), activation = 'relu', input_shape = X_train.shape[1:]))\nmodel.add((MaxPooling2D(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3,3), activation=\"relu\"))\nmodel.add((MaxPooling2D(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, (3,3), activation=\"relu\"))\nmodel.add((MaxPooling2D(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation=\"relu\"))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(2, activation=\"sigmoid\"))\n\nmodel.compile(optimizer=\"adam\",\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history= model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val,y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = model.evaluate(X_test, y_test, verbose = 1)\nprint('\\n','Test_Accuracy:-', accuracy[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = pd.DataFrame(history.history)\nprint(hist)\nhist['epoch'] = history.epoch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_history():\n    plt.figure()\n    plt.xlabel('Epoch')\n    plt.ylabel('Catecorical crossentropy')\n    plt.plot(hist['epoch'], hist['val_accuracy'], label='Val Accuracy')\n    plt.plot(hist['epoch'], hist['val_loss'], label = 'Val Loss')\n    plt.legend()\n    plt.ylim([0,2])\n\nplot_history()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}